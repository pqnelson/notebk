\documentclass{article}



\usepackage[12hr,us]{datetime}
\usepackage{macros}
\usepackage{danger}
\usepackage{notation}
\usepackage[equation,leqno]{deriv}

\def\homeurl{\url{https://pqnelson.github.io/notebk/}}



\title{Elementary Linear Algebra}
\author{Alex Nelson\thanks{This is a page from \homeurl{}\hfil\break\indent\;\, Compiled:\enspace\today\ at \currenttime\ (PST)}}
\date{October 26, 2022}



\begin{document}%\tracingall
\maketitle
TODO: finish proof of Theorem~\ref{thm:basis:inverse-matrix}.

TODO: define the kernel, injective, surjective, bijective.

TODO: move out the eigenstuff from linear transformations to...eigenstuff.

\tableofcontents
\include{tex/preface}

\part{Problem Statement}
\input{tex/systems-of-equations}
\part{Matrices}\label{part:matrices}
\input{tex/matrix-zoo}
\input{tex/matrix-algebra}
\input{tex/augmented-matrix}
\input{tex/determinant}
% \input{tex/eigenstuff}

\vfill\eject
\part{Vector Spaces}

\N*{Roadmap}
We could stop here and die happily (after all, we have introduced a way
to solve systems of linear equations using matrices, which was our
mission statement), but it would be a shallow
life. Instead, we will discuss one more layer of abstraction, one more
shiny gadget that will help us understand systems of linear equations
more profoundly: vector spaces. We can meaningfully discuss ``spaces of
solutions'' to a problem, and it's the laboratory of mathematics which
showcases ``how mathematicians do stuff''.

% Vectors in R^{n}
\input{tex/vectors-in-r-n}
\input{tex/vector-spaces}
\input{tex/subspaces}
\input{tex/basis}
\input{tex/linear-transformations}
% Sections left to write:
% - Linear Transformations
% - Change of Coordinates
% - Orthogonal Complement of Subspaces
% - Constructing Orthonormal Bases
% - Eigendecomposition(???)
% - Rank-Nullity Theorem

\vfill\eject
\part{Appendices}
\appendix
%\include{tex/appendix-1-style}
\input{tex/appendix-sraffa}\vfill\eject
\include{tex/bib}


\end{document}
